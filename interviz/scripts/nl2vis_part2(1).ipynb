{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18574e16-dc4b-4766-a476-05008d20aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79ce2a89-d351-40d4-a356-3e898d1fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\" ## key idea \n",
    "openai.api_key = \"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\" ## key nancy.zwx\n",
    "openai.api_key = \"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\" ## key weixuzhang260 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8da11065-0052-4d12-8a64-99b2c22ed05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, mateys all o'er the world! Set sails, for we've charted treasure most rare in the digit sea - a gem just as enchantin', as the goddess Calypso herself! This sweet delectation be named ChatGPT API. It be the doin’ o' the able-bodied folk at OpenAI.\n",
      "\n",
      "Batten down the hatches, for this be no ordinary treasure! The ChatGPT API allows ye to use the wit o' a model trained by OpenAI to craft stories, answer queries, or just chit-chat in the language of man...or pirate. Aye, ye heard it straight, mateys, this tool will let ye banter in any way ye wish.\n",
      "\n",
      "Interaction be as simple as givin' a system message to set the conversation context, followin' it with several user messages, and the ChatGPT API will give back a model message. Aye, ye can control where the chat be headin’ with 'system level instructions'.\n",
      "\n",
      "And for all ye lads worried 'bout the depths of yer coin purse, fear not, as the cost be calculated based on the number of tokens. Response times can vary, but ye can guide 'em by the max tokens parameter.\n",
      "\n",
      "So, warp yer trusty ship to OpenAI's docks and snatch this paragon of a tech up, afore it be lost in the abyss. Shiver me timbers, it's a fine day to be a tech-lovin' pirate, ain’t it now?\n"
     ]
    }
   ],
   "source": [
    "### Basic Use\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Tell the world about the ChatGPT API in the style of a pirate.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f6ac9-bf64-4023-9753-5959c76afc7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 2: Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221da1f-91a7-4bd5-80e1-07eb9f076e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n"
     ]
    }
   ],
   "source": [
    "with open('schemas_train.json', 'r') as file:\n",
    "    schemas = json.load(file)\n",
    "instruction='''\n",
    "You are a data synthesizer tasked with generating data visualization queries based on the provided database schema. Follow the instructions below to generate the dataset:\n",
    "1. Create a sequence of queries comprising 2-4 rounds of interactions. Every interaction includes: the natural language query, the corresponding Vega-lite code and Visualization Query Languages (VQL), which is a SQL-like pseudo syntax for combining database querying with visual representation directives. Fro example, the VQL query corresponding to the natural language query \"Show a bar chart of the number of faculty members grouped by their rank and gender\" is:  Visualize BAR SELECT Rank, count(*) FROM Faculty GROUP BY Sex, Rank.\n",
    "2. Queies in a sequence should form a meaningful and coherent conversation flow, establishing dependencies and connections between queries. The context dependency types include \"Independent\",\"Coreference\" and \"Ellipsis\". For example, in a conversation like \"Show me flights from New York.\" - \"What about to Chicago?\", the second query is context-dependent, as its meaning relies on the first query. The dependency types can be \"Coreference\", which involves referring back to an entity or concept from a previous query without directly stating it, or \"Ellipsis\", where certain parts of a query are omitted because they can be inferred from the previous context. Only the first query in the sequence can be \"Independent\"\n",
    "3. Aim to include diverse visualization types such as bar charts, line charts, pie charts, scatter charts, etc.\n",
    "4. Format every query into a dictionary including \"Natural Language Query\", \"Vega-lite Code\", \"VQL\" and \"Context Denpendency Type\". The Vega-lite code doesn't need keys of 'data' or 'schema'.\n",
    "5. Concat the sequence into a list\n",
    "6. Output the conversation in JSON format as a list of dictionaries. The output should be a valid JSON code without any accompanying text explanations. Ensure that the JSON code can be executed without any issues.\n",
    "Input:\n",
    "'''\n",
    "# predictions = []\n",
    "\n",
    "def generate_chat_response(messages):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=messages,\n",
    "                # temperature=0.2,\n",
    "                max_tokens=3000,\n",
    "                timeout=600,\n",
    "            )\n",
    "            chat_response= completion.choices[0].message.content\n",
    "            return chat_response\n",
    "        except Exception as e:\n",
    "            error_message = \"An error occurred: \" + str(e)\n",
    "            print(error_message)\n",
    "\n",
    "def process_chat_response(chat_response):\n",
    "    while True:\n",
    "        json_matches = re.findall(r\"```(.*?)```\", chat_response, re.DOTALL)\n",
    "        json_str = json_matches[0].strip().replace(\"json\", \"\") if json_matches else chat_response\n",
    "        cleaned_json = re.sub(r'([{,])(\\s*)([a-zA-Z0-9_]+)\\s*:', r'\\1\"\\3\":', json_str)\n",
    "        try:\n",
    "            lst = json.loads(cleaned_json)\n",
    "            return lst\n",
    "        except Exception as e:\n",
    "            error_message = \"An error occurred: \" + str(e)\n",
    "            print(error_message)\n",
    "            messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"user\", \"content\": schema}] \n",
    "            chat_response= generate_chat_response(messages)\n",
    "        \n",
    "for schema in schemas[111:]: \n",
    "  for _ in range(20):\n",
    "    messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"user\", \"content\": schema}] \n",
    "    # messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"system\", \"content\": example},{\"role\": \"user\", \"content\": schema}] \n",
    "    chat_response= generate_chat_response(messages)\n",
    "    lst = process_chat_response(chat_response)\n",
    "    for item in lst:\n",
    "        item['Database Schema']=schema\n",
    "    predictions.append(lst)\n",
    "    print(len(predictions))\n",
    "    with open(\"vql_schema_train.json\", \"w\") as file:\n",
    "        json.dump(predictions, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8e17c21-d120-445d-8c80-397f9dc6e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "with open(\"vql_schema_train.json\", \"w\") as file:\n",
    "    json.dump(predictions, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6b23b37-b30e-4fb6-96c0-42545dd22cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220\n"
     ]
    }
   ],
   "source": [
    "predictions=predictions[0:2220]\n",
    "print(len(predictions))\n",
    "with open(\"vql_schema_train.json\", \"w\") as file:\n",
    "    json.dump(predictions, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3e68d-1736-47a0-b0ad-36b9d8feacd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

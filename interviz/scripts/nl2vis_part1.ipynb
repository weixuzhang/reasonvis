{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18574e16-dc4b-4766-a476-05008d20aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79ce2a89-d351-40d4-a356-3e898d1fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\" ## key nancy.zwx\n",
    "openai.api_key = \"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\" ## key weixuzhang260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da11065-0052-4d12-8a64-99b2c22ed05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic Use\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Tell the world about the ChatGPT API in the style of a pirate.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f6ac9-bf64-4023-9753-5959c76afc7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1: Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c421412-8e0a-499f-a5fd-825b8ed05e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_dataset(data_path):\n",
    "    with open(data_path, encoding=\"utf-8\") as f:\n",
    "        lst_dict = json.load(f)\n",
    "    lst_strings = []\n",
    "    for item in lst_dict:\n",
    "        string = json.dumps(item, ensure_ascii=False)\n",
    "        lst_strings.append(string)\n",
    "    return lst_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221da1f-91a7-4bd5-80e1-07eb9f076e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions=serialize_dataset(\"interactions_dev_withoutdata.json\")\n",
    "instruction='''\n",
    "You are a data synthesizer tasked with generating data visualization queries based on the natural language queries and their corresponding Vega-lite code. Follow the instructions below to generate the dataset:\n",
    "1. The desired data visualization query format is Visualization Query Languages (VQL), a SQL-like pseudo syntax for combining database querying with visual representation directives. Fro example, the VQL query corresponding to the natural language query \"Show a bar chart of the number of faculty members grouped by their rank and gender\" is:  Visualize BAR SELECT Rank, count(*) FROM Faculty GROUP BY Sex, Rank.\n",
    "2. Format every query into a dictionary including \"Natural Language Query\", \"Vega-lite Code\" and \"VQL\"\n",
    "3. Concat the sequence into a list\n",
    "4. Output the conversation in JSON format as a list of dictionaries. The output should be a valid JSON code without any accompanying text explanations. Ensure that the JSON code can be executed without any issues.\n",
    "Input:\n",
    "'''\n",
    "# predictions = []\n",
    "\n",
    "def generate_chat_response(messages):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "                max_tokens=3000,\n",
    "                timeout=600,\n",
    "            )\n",
    "            chat_response= completion.choices[0].message.content\n",
    "            return chat_response\n",
    "        except Exception as e:\n",
    "            error_message = \"An error occurred: \" + str(e)\n",
    "            print(error_message)\n",
    "\n",
    "def process_chat_response(chat_response):\n",
    "    while True:\n",
    "        json_matches = re.findall(r\"```(.*?)```\", chat_response, re.DOTALL)\n",
    "        json_str = json_matches[0].strip().replace(\"json\", \"\") if json_matches else chat_response\n",
    "        cleaned_json = re.sub(r'([{,])(\\s*)([a-zA-Z0-9_]+)\\s*:', r'\\1\"\\3\":', json_str)\n",
    "        try:\n",
    "            lst = json.loads(cleaned_json)\n",
    "            return lst\n",
    "        except Exception as e:\n",
    "            error_message = \"An error occurred: \" + str(e)\n",
    "            print(error_message)\n",
    "            messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"user\", \"content\": interaction}] \n",
    "            chat_response= generate_chat_response(messages)\n",
    "\n",
    "for interaction in interactions[173:]: \n",
    "    messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"user\", \"content\": interaction}] \n",
    "    # messages = [{\"role\": \"system\", \"content\": instruction},{\"role\": \"system\", \"content\": example},{\"role\": \"user\", \"content\": interaction}]\n",
    "    chat_response= generate_chat_response(messages)\n",
    "    lst = process_chat_response(chat_response)\n",
    "    predictions.append(lst)\n",
    "    print(len(predictions))\n",
    "    with open(\"vql_interactions_dev_2.json\", \"w\") as file:\n",
    "        json.dump(predictions, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0e1e669-72ed-4db7-873f-2885d8b38a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "with open(\"vql_interactions_dev_2.json\", \"w\") as file:\n",
    "    json.dump(predictions, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fccb87-0254-4da3-a955-0664d4f9da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vql_interactions_train_withschema.json', 'r') as file:\n",
    "    inter_1 = json.load(file)\n",
    "with open('vql_interactions_train_noschema.json', 'r') as file:\n",
    "    inter_2 = json.load(file)\n",
    "for interaction in inter_1:\n",
    "    for query in interaction:\n",
    "        del query[\"Database Schema\"]\n",
    "inter=inter_1+inter_2\n",
    "with open(\"vql_interactions_train.json\", \"w\") as file:\n",
    "    json.dump(inter, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
